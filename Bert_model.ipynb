{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5BEJD0LAV209CuvY58K+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76f3fd3fd9b34e789e7a129827b85c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_274aa4bf8be84f80baa77fd64368804b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60ecce5f43504a6cb72f61dc1f05360b",
              "IPY_MODEL_8a8ea54457fa448ba67bfaa0acd67a52"
            ]
          }
        },
        "274aa4bf8be84f80baa77fd64368804b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60ecce5f43504a6cb72f61dc1f05360b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_169c0025ae4342278d23b3797e9e9c00",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f25c525192741e99499da9eb92fb09b"
          }
        },
        "8a8ea54457fa448ba67bfaa0acd67a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01d5df5ce77c4ed19d31e4b489413307",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bd2c2ff46fb49b182f0d51b302adfb6"
          }
        },
        "169c0025ae4342278d23b3797e9e9c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f25c525192741e99499da9eb92fb09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01d5df5ce77c4ed19d31e4b489413307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bd2c2ff46fb49b182f0d51b302adfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3cabad8334c4af991b16e2d01637570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92762ca52d40475c9c80861f30bd247f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36ee34e115324bd394cbdb4baf12afa5",
              "IPY_MODEL_4e6f69d62f534a2bbdc82654e256bf40"
            ]
          }
        },
        "92762ca52d40475c9c80861f30bd247f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36ee34e115324bd394cbdb4baf12afa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e432cc7449148e88fcff0f4a418f3e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f43b079d198047058511e737976da239"
          }
        },
        "4e6f69d62f534a2bbdc82654e256bf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c15b6523235b457db9bd66e1672af3a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.16kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90754130a8444570b85266e4690f4277"
          }
        },
        "5e432cc7449148e88fcff0f4a418f3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f43b079d198047058511e737976da239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c15b6523235b457db9bd66e1672af3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90754130a8444570b85266e4690f4277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004bfd9fb73c48e6ac00cdf5bc57b88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42cf748537ee4d3db65b88f0581d580d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96a0767e43ae41888ec8d9206c1e9537",
              "IPY_MODEL_65ccd1c25f1d4a65a13f0cd6652713e5"
            ]
          }
        },
        "42cf748537ee4d3db65b88f0581d580d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96a0767e43ae41888ec8d9206c1e9537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c30d95bbd3e43edbadf9eec16669ef2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60e45f3008874a8faba45995f8376f91"
          }
        },
        "65ccd1c25f1d4a65a13f0cd6652713e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4fc28d7e0d74d3b9aca68071d119acd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:29&lt;00:00, 14.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1939b4a382b43c79d4bd00704e4b77f"
          }
        },
        "8c30d95bbd3e43edbadf9eec16669ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60e45f3008874a8faba45995f8376f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4fc28d7e0d74d3b9aca68071d119acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1939b4a382b43c79d4bd00704e4b77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericpapain/DiscriminationTweetsProject/blob/master/Bert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eosrJjJa4pBo",
        "outputId": "b74d2801-ffb5-4942-d993-f268ec27003c"
      },
      "source": [
        "### Initialisation de Collab dans mon drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_QuyqfP56ER"
      },
      "source": [
        "## **1. Import dataset and librairies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OveyvAgP6Czz"
      },
      "source": [
        "#### *1.1 Import Librairies*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7HQmqIP6LRt",
        "outputId": "cf4e5986-c483-46d9-e70a-466f41470b1f"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/96/827c132397d0eb5731c1eda05dbfb019ede064ca8c7d0f329160ce0a4acd/pyspellchecker-0.5.5-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Y3ubXL6E_-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from spellchecker import SpellChecker\n",
        "import requests\n",
        "from datetime import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-g7WecH6UTz"
      },
      "source": [
        "#### *1.2 Import dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZnNYw-E6OqV"
      },
      "source": [
        "dataset = pd.read_csv('discrimination.csv', sep=',')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMgp_Sj26XAN"
      },
      "source": [
        "discriminant_Dataset = dataset.iloc[:,[1,3]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwCM-ZHx8Y4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d705558-e693-4f2c-ef33-72dc045df848"
      },
      "source": [
        "discriminant_Dataset.sample"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.sample of                                                   Tweets  Labels\n",
              "0      @TVBachelor @NewJerzeyBoy what about the femin...       1\n",
              "1      @ThelmaSleaze uh... did you watch the video? o...       1\n",
              "2      Managed to hit a bird and a small rodent on my...       1\n",
              "3      If you believe a #holohoax or #gays, LGBT &amp...       1\n",
              "4      Rid yourself of #Feminazi, #Fag &amp; #Jewf. E...       1\n",
              "...                                                  ...     ...\n",
              "22899  #MKR that wiped that horrible smile off Kat's ...       1\n",
              "22900  RT @Oneiorosgrip: #adviceforyoungfeminists Lea...       1\n",
              "22901  RT @Keltonsexy250 I'm concerned for the girls ...       1\n",
              "22902  RT @melbsonmymind: NO. NO NO NO NO NO NO NO. G...       1\n",
              "22903  A hit with 5-year-olds @adnan_bahatti55 Don't ...       1\n",
              "\n",
              "[22904 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lIwd7e6_Ju6"
      },
      "source": [
        "## **2. Tokenization and Input Formatting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcghjPv1-Wfq"
      },
      "source": [
        "def data_cleaning(dataset):\n",
        "    '''\n",
        "        df : DataFrame \n",
        "    '''\n",
        "    #capture du temps d'exécution du programme\n",
        "    start_time = datetime.now()\n",
        "    for i in range(len(dataset)):\n",
        "        # Mise en minuscule \n",
        "        dataset['Tweets'][i] = dataset['Tweets'][i].lower()\n",
        "        #suppression des carractère spéciaux\n",
        "        dataset['Tweets'][i]=re.sub(r'(&#[0-9]*;)', ' ',dataset['Tweets'][i])\n",
        "        #suppression des annotations, des noms et tag inutile\n",
        "        dataset['Tweets'][i]=re.sub(r'(@.*?)[\\s]', ' ',dataset['Tweets'][i])\n",
        "        # Replace '&amp;' par '&'\n",
        "        dataset['Tweets'][i] = re.sub(r'&amp;', '&', dataset['Tweets'][i])\n",
        "        #suppression urls\n",
        "        dataset['Tweets'][i]=re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' ',dataset['Tweets'][i])\n",
        "        #suppression des retweets\n",
        "        dataset['Tweets'][i]=re.sub(r'rt', ' ',dataset['Tweets'][i])\n",
        "        # Suppression des espaces de fin de ligne\n",
        "        dataset['Tweets'][i] = re.sub(r'\\s+', ' ', dataset['Tweets'][i]).strip()\n",
        "  \n",
        "    #capture temps de fin\n",
        "    end_time = datetime.now()\n",
        "    print(\">>>>> le data cleanning à pris :\",(end_time-start_time),\" secondes.\")\n",
        "    return dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG9pCfIx_pWg"
      },
      "source": [
        "### *- Gestion des mots ecris en verlang, argo, etc...*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8yIHSX0_mOu"
      },
      "source": [
        "#parcours de chaque mot dans un tweet\n",
        "def remplace_word_abbreviation(dataset_clean,file_txt):\n",
        "    start_time = datetime.now()\n",
        "    list_word=[]\n",
        "    new_list_word=[]\n",
        "    dico_word_abrev={}\n",
        "    #chargement du dico des abrev\n",
        "    a_file = open(file_txt)\n",
        "    for line in a_file:\n",
        "        value = line.split(\",\")\n",
        "        #list_word.append(value)\n",
        "    for val in value:\n",
        "        valN = val.strip(\"{}\")\n",
        "        list_word.append(valN)\n",
        "    for val in list_word:\n",
        "        valN = val.split(\":\")\n",
        "        try:\n",
        "            key = valN[0]\n",
        "            val_key = valN[1]\n",
        "            dico_word_abrev[key] = val_key\n",
        "        except:\n",
        "            #print(key, \"------------------------\",val_key)\n",
        "            del val\n",
        "            pass\n",
        "    for word_dico,values in dico_word_abrev.items():\n",
        "        for i in range(len(dataset_clean)):\n",
        "            tweet = list((dataset_clean['Tweets'][i]).split())\n",
        "            #positionnement au premier mot\n",
        "            j=0\n",
        "            for word in tweet:\n",
        "                #recupération du mot en non abrégé\n",
        "                if(word == word_dico):\n",
        "                    #remplacement dans le tweet\n",
        "                    tweet[j]=values\n",
        "                #tweet suivant\n",
        "                j=j+1\n",
        "            if(j==0):\n",
        "                pass\n",
        "            else:\n",
        "                #mise a jour du tweet dans le dataset\n",
        "                dataset['Tweets'][i] = ' '.join(tweet)\n",
        "            #if(i==len(dataset_clean)-1):\n",
        "                #print(i)\n",
        "    end_time = datetime.now()\n",
        "    print(\">>>>> le remplacement des mots abégé et ecris en argo à pris :\",(end_time-start_time),\" secondes.\")\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRaAVHit_un4"
      },
      "source": [
        "### *- Gestion des fautes de grammaires et d'orthographe, mots mal écris etc ...*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Si8WCkj_saM"
      },
      "source": [
        "#recherche de mot mal écrit\n",
        "def spelling_word_in_tweet(dataset_clean):\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    spell = SpellChecker(language='en',distance=1)\n",
        "    dico_correction_orthographe = {}\n",
        "    \n",
        "    for i in range(len(dataset_clean)):\n",
        "        tweet = list((dataset_clean['Tweets'][i]).split())\n",
        "        j=0\n",
        "        for word in tweet:\n",
        "            # Get the one `most likely` answer\n",
        "            #print(\"next : \",word,\" newww :\",spell.correction(word))\n",
        "            mot = spell.correction(word)\n",
        "            # Get a list of `likely` options\n",
        "           # print(spell.candidates(word))\n",
        "            if(mot==word):\n",
        "                pass\n",
        "            else:\n",
        "                #construction du dico des abréviation trouvé\n",
        "                #print(mot,word)\n",
        "                dico_correction_orthographe[word]=mot\n",
        "                tweet[j]=mot\n",
        "                #print(\"tweet number : \",i,\" i was :\",word,\" now i'm \",true_val)\n",
        "            j=j+1\n",
        "            #print(r.text[startIndex:endIndex])\n",
        "        if(j==0):\n",
        "            pass\n",
        "        else:\n",
        "            #mise a jour du tweet\n",
        "            dataset_clean['Tweets'][i] = ' '.join(tweet)\n",
        "            dataset_clean['Tweets'][i] = dataset_clean['Tweets'][i].lower()\n",
        "        #if((i+1)%len(dataset_clean)==0):\n",
        "            #print(i,\": tous les tweets ont été corrigé !!!\")\n",
        "    \n",
        "    end_time = datetime.now()\n",
        "    print(\">>>>> le remplacement des mots mal écris ( fautes d'othographes et de grammaires) à pris :\",(end_time-start_time),\" secondes.\")\n",
        "    \n",
        "    return dico_correction_orthographe, dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58KiozE7mkJH"
      },
      "source": [
        "### *- Fonctions de prétraitement*\n",
        "- datacleaning\n",
        "- gestion abreviation\n",
        "- gestion des spelling word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEe40q8G_x6R"
      },
      "source": [
        "def traitemnet_before_bert_tokenization(dataset):\n",
        "    #import file abrev \n",
        "    file = \"dico_abrev.txt\"\n",
        "    # small cleaning\n",
        "    dataset_clean=data_cleaning(dataset)\n",
        "    # abreviation subtitution\n",
        "    dataset_with_abrev_ok=remplace_word_abbreviation(dataset_clean,file)\n",
        "    # manage spelling word\n",
        "    _, dataset_spell_ok=spelling_word_in_tweet(dataset_with_abrev_ok)\n",
        "    \n",
        "    return dataset_spell_ok"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Wxj_AMnRPV"
      },
      "source": [
        "## *------ Lancement du pretraitement sur notre jeu de donnée -----*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9JfDXTM_0YF",
        "outputId": "13846053-4de7-4c7f-d64c-f35a537abc1b"
      },
      "source": [
        "#small traitemnt\n",
        "discriminant_Dataset = traitemnet_before_bert_tokenization(discriminant_Dataset)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>> le data cleanning à pris : 0:00:36.336909  secondes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>> le remplacement des mots abégé et ecris en argo à pris : 0:49:48.832839  secondes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>> le remplacement des mots mal écris ( fautes d'othographes et de grammaires) à pris : 0:00:58.365109  secondes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfPZ96dSn71x"
      },
      "source": [
        "### *--- Division de notre jeux de donnée en jeu d'entrainement et de test ---*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gwsCIJJ6cWj"
      },
      "source": [
        "# division de notre jeu de donnée en jeu d'entrainement et de test\n",
        "discriminant_Dataset['split']= np.random.randn(discriminant_Dataset.shape[0], 1)\n",
        "msk = np.random.rand(len(discriminant_Dataset)) <= 0.9\n",
        "#data_train et data_test\n",
        "data_train = discriminant_Dataset[msk]\n",
        "data_test = discriminant_Dataset[~msk]\n",
        "\n",
        "data_train = data_train.iloc[:,[1,3]]\n",
        "data_test = data_test.iloc[:,[1,3]]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrTbQlSm_60O"
      },
      "source": [
        "#### *Training/Validation Split*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D703_ETa_9Xm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3cbQqI0AUbW"
      },
      "source": [
        "#for discriminant data\n",
        "X_discri_train, X_discri_val, y_discri_train, y_discri_val = train_test_split(data_train['Tweets'], \n",
        "                                                  data_train['Labels'], \n",
        "                                                  test_size=0.10, \n",
        "                                                  random_state=2020, \n",
        "                                                  stratify=data_train['Labels'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqlYjFOVAl73"
      },
      "source": [
        "#### *2.1. BERT Tokenizer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNTu7KsaCQW",
        "outputId": "5eb375af-62f8-48bc-ca20-e913e6c16e0a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 11.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 6.7MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=35b231747f10115b40374437e48c0e1aac9621c58c7f2a275468812d7482ec18\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLpiKAomowh9"
      },
      "source": [
        "### *-Chargement du tokenizer de BERT*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "76f3fd3fd9b34e789e7a129827b85c61",
            "274aa4bf8be84f80baa77fd64368804b",
            "60ecce5f43504a6cb72f61dc1f05360b",
            "8a8ea54457fa448ba67bfaa0acd67a52",
            "169c0025ae4342278d23b3797e9e9c00",
            "1f25c525192741e99499da9eb92fb09b",
            "01d5df5ce77c4ed19d31e4b489413307",
            "7bd2c2ff46fb49b182f0d51b302adfb6"
          ]
        },
        "id": "fHuVQXoiAnOh",
        "outputId": "fe9697d0-1375-4366-cba5-d247a09b6109"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "# Chargement du tokenizer de Bert\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76f3fd3fd9b34e789e7a129827b85c61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6f_0FLpGfG"
      },
      "source": [
        "### *-Recherche de la chaine la plus longue dans nos tweet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-mtKeHEAuG-",
        "outputId": "ddaea131-c772-4be7-f643-528fb366e719"
      },
      "source": [
        "#extraction de nos tweets\n",
        "all_tweets = dataset.Tweets.values\n",
        "# Encodage de notre dataset en une liste liste pour rechercher le la chaine la plus longue de notre dataset\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# recherche du tweet le plus long\n",
        "MAX_LEN = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', MAX_LEN)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUJIBc3pcs5"
      },
      "source": [
        "### *--Définir fonction de pré processing pour BERT en utilisant son tokenizer définie plus haut--*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3UHcUeMAu_O"
      },
      "source": [
        "# Fonction de tokenization de notre corpus\n",
        "def preprocessing_for_bert(data_after_clean):\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # creation de liste vide pour sauvegarder les sorties ( mask et token)\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # pour chaque phrase,\n",
        "    for sent in data_after_clean:\n",
        "        # `encode_plus` permet de:\n",
        "        #    (1) Tokenizer les phrases\n",
        "        #    (2) Ajoute les tokens `[CLS]` et `[SEP]` pour marquer le debut et la fin d'une phrase\n",
        "        #    (3) Map les tokens avec leurs IDs respectifs\n",
        "        #    (4) Crée le mask d'attention\n",
        "        #    (5) Retourne un dictionnaire en sortie\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,                           #chargement des phrases du corpus\n",
        "            add_special_tokens=True,        #ajout des tokens de debut `[CLS]` et fin de ligne `[SEP]`\n",
        "            max_length=MAX_LEN,             #Max lenght\n",
        "            pad_to_max_length=True,         \n",
        "            return_attention_mask=True      #attention mask\n",
        "            )\n",
        "        \n",
        "        # ajout des sorties apres tokenization dans les listes créer plus haut\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Converssion des listes en tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    print(\">>>>> La Tokenization à pris :\",(end_time-start_time),\" secondes.\")\n",
        "    \n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeICXGFHA1SA"
      },
      "source": [
        "### -------------Tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhYkVo4PAzAm",
        "outputId": "04781c05-be4f-45c2-ca2f-056732f0bc6c"
      },
      "source": [
        "#lancememnt de la fonction `preprocessing_for_bert` sur le jeu d'entrainement et de validation pour le discriminant dataset\n",
        "print('Tokenizing data...')\n",
        "train_discr_inputs, train_discr_masks = preprocessing_for_bert(X_discri_train)\n",
        "val_discr_inputs, val_discr_masks = preprocessing_for_bert(X_discri_val)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>> La Tokenization à pris : 0:00:08.416711  secondes.\n",
            ">>>>> La Tokenization à pris : 0:00:00.947001  secondes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7NgR7J8BAWN"
      },
      "source": [
        "### **2.2. Creation de notre DataLoader**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emQgVCfVBCxE"
      },
      "source": [
        "Nous allons créer ici un itérateur pour notre ensemble de données à l'aide de la classe Torch DataLoader. Cela aidera à économiser de la mémoire pendant l'entraînement et à augmenter la vitesse d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELueY8svBA-O"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Pour affiner BERT, les auteurs recommandent une taille de batch de 16 ou 32, nous prendrons 32.\n",
        "batch_size = 32"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZTSl99aBFuH"
      },
      "source": [
        "# convertion de nos label en tensors pour la manipulation par le GPU\n",
        "train_discri_labels = torch.tensor(y_discri_train.values)\n",
        "val_discri_labels = torch.tensor(y_discri_val.values)\n",
        "\n",
        "# Creation de notre dataloader pour le training set pour le discrimination dataset\n",
        "train_discri_data = TensorDataset(train_discr_inputs, train_discr_masks, train_discri_labels)\n",
        "train_d_sampler = RandomSampler(train_discri_data)\n",
        "train_discri_dataloader = DataLoader(train_discri_data, sampler=train_d_sampler, batch_size=batch_size)\n",
        "\n",
        "# Creation de notre dataloader pour le validation set pour le discrimination dataset\n",
        "val_discri_data = TensorDataset(val_discr_inputs, val_discr_masks, val_discri_labels)\n",
        "val_d_sampler = SequentialSampler(val_discri_data)\n",
        "val_discri_dataloader = DataLoader(val_discri_data, sampler=val_d_sampler, batch_size=batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcKj6JQ7BOxA"
      },
      "source": [
        "## **3. Entrainement de notre Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBW6vzlxBWIg"
      },
      "source": [
        "#### *3.1. Create BertClassifier*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6b9ec0rBQ36",
        "outputId": "9e14c629-18d9-40c5-d89e-bd5413f5b793"
      },
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model pour la classififcation implémenter avec tous les paramètres de zéro.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: le model objet de BertModel\n",
        "        @param    classifier: le module reseau de neurone de pytoch torch.nn.Module\n",
        "        @param    freeze_bert (bool): Set `False` pour activer ou désactiver le fine-tune du model de  BERT\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specifions les différentes couches et nombre d'entrée de neuronnes: hidden size pour BERT, hidden size pour notre classifier, et nombre de labels (sortie : 2 pour 0 ou 1)\n",
        "        D_in, H, D_out = 768, 200, 2\n",
        "\n",
        "        # Initialisation du model de BERT\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # instanciation du modèle et mise en place du one-layer feedforward\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # ici, on Freeze le BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        # Feed l'entrée a BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extraction de la dernier etat de la derniere couche du token du debut de ligne `[CLS]` pour la classififcation de la tache\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed l'entrée du classifier pour calculer les logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 44 µs, sys: 0 ns, total: 44 µs\n",
            "Wall time: 47.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khkRrG4HBaaM"
      },
      "source": [
        "#### *3.2. Optimizer & Learning Rate Scheduler*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOr-lVARBcYD"
      },
      "source": [
        "Pour affiner notre modèle de classification de Bert conçu, nous devons créer un optimiseur. Les auteurs recommandes d'utiliser les hyper-parameters ci-dessous:\n",
        "\n",
        "- Batch size: 16 ou 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
        "- Nombre d'epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC1lhp2CBfkt"
      },
      "source": [
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialisation de notre Bert Classifier, optimizer et du learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiation de Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Choix du GPU ou CPU\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Creation de l'optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Nombre totale d'etape d'entrainement(elle depend fortement de la taille de notre dataloader d'entrainement)\n",
        "    total_steps = len(train_discri_dataloader) * epochs\n",
        "\n",
        "    # Configuration de notre leaning rate(taux d'apprentissage)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrphamqHBkWO"
      },
      "source": [
        "#### *3.3. Boucle d'entrainement*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA27MZ2DBlOx"
      },
      "source": [
        "We will train our Bert Classifier for 4 epochs. In each epoch, we will train our model and evaluate its performance on the validation set. In more details, we will:\n",
        "\n",
        "Training:\n",
        "- Unpack our data from the dataloader and load the data onto the GPU\n",
        "- Zero out gradients calculated in the previous pass\n",
        "- Perform a forward pass to compute logits and loss\n",
        "- Perform a backward pass to compute gradients (loss.backward())\n",
        "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "- Update the model's parameters (optimizer.step())\n",
        "- Update the learning rate (scheduler.step())\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "- Unpack our data and load onto the GPU\n",
        "- Forward pass\n",
        "- Compute loss and accuracy rate over the validation set\n",
        "\n",
        "The script below is commented with the details of our training and evaluation loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jNQ6gNJBoTL"
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    start_time = datetime.now()\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            \n",
        "            # Tell PyTorch to run the model on GPU or cpu\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            # Load batch to GPU or CPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    end_time = datetime.now()\n",
        "    print(\">>>>>Training complete! in \",(end_time-start_time),\" secondes.\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Tell PyTorch to run the model on GPU or cpu\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # Load batch to GPU or CPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liu454_UB3_C"
      },
      "source": [
        "#### **----, Début de notre entrainement du BertClassifier!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3cabad8334c4af991b16e2d01637570",
            "92762ca52d40475c9c80861f30bd247f",
            "36ee34e115324bd394cbdb4baf12afa5",
            "4e6f69d62f534a2bbdc82654e256bf40",
            "5e432cc7449148e88fcff0f4a418f3e8",
            "f43b079d198047058511e737976da239",
            "c15b6523235b457db9bd66e1672af3a6",
            "90754130a8444570b85266e4690f4277",
            "004bfd9fb73c48e6ac00cdf5bc57b88c",
            "42cf748537ee4d3db65b88f0581d580d",
            "96a0767e43ae41888ec8d9206c1e9537",
            "65ccd1c25f1d4a65a13f0cd6652713e5",
            "8c30d95bbd3e43edbadf9eec16669ef2",
            "60e45f3008874a8faba45995f8376f91",
            "a4fc28d7e0d74d3b9aca68071d119acd",
            "f1939b4a382b43c79d4bd00704e4b77f"
          ]
        },
        "id": "h26e7f74B52N",
        "outputId": "d3cd606f-dc93-43d5-9844-bd01f62a2824"
      },
      "source": [
        "set_seed(42)    # configuration de notre modèle de reproduction\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
        "train(bert_classifier, train_discri_dataloader, val_discri_dataloader, epochs=4, evaluation=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3cabad8334c4af991b16e2d01637570",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004bfd9fb73c48e6ac00cdf5bc57b88c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.549333   |     -      |     -     |   8.86   \n",
            "   1    |   40    |   0.447538   |     -      |     -     |   8.24   \n",
            "   1    |   60    |   0.403378   |     -      |     -     |   8.23   \n",
            "   1    |   80    |   0.371309   |     -      |     -     |   8.25   \n",
            "   1    |   100   |   0.367845   |     -      |     -     |   8.25   \n",
            "   1    |   120   |   0.407649   |     -      |     -     |   8.32   \n",
            "   1    |   140   |   0.330451   |     -      |     -     |   8.34   \n",
            "   1    |   160   |   0.334221   |     -      |     -     |   8.35   \n",
            "   1    |   180   |   0.337078   |     -      |     -     |   8.36   \n",
            "   1    |   200   |   0.336636   |     -      |     -     |   8.36   \n",
            "   1    |   220   |   0.393367   |     -      |     -     |   8.40   \n",
            "   1    |   240   |   0.349791   |     -      |     -     |   8.45   \n",
            "   1    |   260   |   0.328258   |     -      |     -     |   8.47   \n",
            "   1    |   280   |   0.284814   |     -      |     -     |   8.53   \n",
            "   1    |   300   |   0.347268   |     -      |     -     |   8.58   \n",
            "   1    |   320   |   0.381764   |     -      |     -     |   8.63   \n",
            "   1    |   340   |   0.349966   |     -      |     -     |   8.66   \n",
            "   1    |   360   |   0.336459   |     -      |     -     |   8.74   \n",
            "   1    |   380   |   0.337490   |     -      |     -     |   8.83   \n",
            "   1    |   400   |   0.334363   |     -      |     -     |   8.86   \n",
            "   1    |   420   |   0.345951   |     -      |     -     |   8.89   \n",
            "   1    |   440   |   0.314337   |     -      |     -     |   8.94   \n",
            "   1    |   460   |   0.306041   |     -      |     -     |   8.86   \n",
            "   1    |   480   |   0.300740   |     -      |     -     |   8.85   \n",
            "   1    |   500   |   0.333646   |     -      |     -     |   8.82   \n",
            "   1    |   520   |   0.329481   |     -      |     -     |   8.79   \n",
            "   1    |   540   |   0.323683   |     -      |     -     |   8.80   \n",
            "   1    |   560   |   0.309218   |     -      |     -     |   8.82   \n",
            "   1    |   580   |   0.291577   |     -      |     -     |   8.73   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.351501   |  0.306621  |   87.57   |  257.60  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.198346   |     -      |     -     |   9.25   \n",
            "   2    |   40    |   0.242708   |     -      |     -     |   8.85   \n",
            "   2    |   60    |   0.235235   |     -      |     -     |   8.81   \n",
            "   2    |   80    |   0.234324   |     -      |     -     |   8.79   \n",
            "   2    |   100   |   0.230764   |     -      |     -     |   8.81   \n",
            "   2    |   120   |   0.279330   |     -      |     -     |   8.80   \n",
            "   2    |   140   |   0.238118   |     -      |     -     |   8.81   \n",
            "   2    |   160   |   0.192519   |     -      |     -     |   8.83   \n",
            "   2    |   180   |   0.205862   |     -      |     -     |   8.82   \n",
            "   2    |   200   |   0.227622   |     -      |     -     |   8.85   \n",
            "   2    |   220   |   0.184775   |     -      |     -     |   8.90   \n",
            "   2    |   240   |   0.222666   |     -      |     -     |   8.86   \n",
            "   2    |   260   |   0.210941   |     -      |     -     |   8.87   \n",
            "   2    |   280   |   0.214484   |     -      |     -     |   8.82   \n",
            "   2    |   300   |   0.216654   |     -      |     -     |   8.87   \n",
            "   2    |   320   |   0.239743   |     -      |     -     |   8.83   \n",
            "   2    |   340   |   0.213384   |     -      |     -     |   8.78   \n",
            "   2    |   360   |   0.238792   |     -      |     -     |   8.83   \n",
            "   2    |   380   |   0.269062   |     -      |     -     |   8.81   \n",
            "   2    |   400   |   0.200108   |     -      |     -     |   8.83   \n",
            "   2    |   420   |   0.243552   |     -      |     -     |   8.83   \n",
            "   2    |   440   |   0.229882   |     -      |     -     |   8.82   \n",
            "   2    |   460   |   0.216569   |     -      |     -     |   8.82   \n",
            "   2    |   480   |   0.149049   |     -      |     -     |   8.80   \n",
            "   2    |   500   |   0.222280   |     -      |     -     |   8.81   \n",
            "   2    |   520   |   0.211183   |     -      |     -     |   8.81   \n",
            "   2    |   540   |   0.233642   |     -      |     -     |   8.82   \n",
            "   2    |   560   |   0.215655   |     -      |     -     |   8.80   \n",
            "   2    |   580   |   0.197924   |     -      |     -     |   8.76   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.221173   |  0.339108  |   88.29   |  264.70  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.093553   |     -      |     -     |   9.23   \n",
            "   3    |   40    |   0.146743   |     -      |     -     |   8.85   \n",
            "   3    |   60    |   0.166622   |     -      |     -     |   8.79   \n",
            "   3    |   80    |   0.098239   |     -      |     -     |   8.80   \n",
            "   3    |   100   |   0.121676   |     -      |     -     |   8.78   \n",
            "   3    |   120   |   0.122890   |     -      |     -     |   8.79   \n",
            "   3    |   140   |   0.127696   |     -      |     -     |   8.81   \n",
            "   3    |   160   |   0.139217   |     -      |     -     |   8.79   \n",
            "   3    |   180   |   0.082996   |     -      |     -     |   8.80   \n",
            "   3    |   200   |   0.124622   |     -      |     -     |   8.75   \n",
            "   3    |   220   |   0.108102   |     -      |     -     |   8.81   \n",
            "   3    |   240   |   0.136354   |     -      |     -     |   8.81   \n",
            "   3    |   260   |   0.114837   |     -      |     -     |   8.79   \n",
            "   3    |   280   |   0.151111   |     -      |     -     |   8.82   \n",
            "   3    |   300   |   0.132940   |     -      |     -     |   8.82   \n",
            "   3    |   320   |   0.134920   |     -      |     -     |   8.76   \n",
            "   3    |   340   |   0.109760   |     -      |     -     |   8.76   \n",
            "   3    |   360   |   0.093802   |     -      |     -     |   8.79   \n",
            "   3    |   380   |   0.127313   |     -      |     -     |   8.81   \n",
            "   3    |   400   |   0.116612   |     -      |     -     |   8.77   \n",
            "   3    |   420   |   0.133155   |     -      |     -     |   8.81   \n",
            "   3    |   440   |   0.172741   |     -      |     -     |   8.80   \n",
            "   3    |   460   |   0.120980   |     -      |     -     |   8.82   \n",
            "   3    |   480   |   0.121993   |     -      |     -     |   8.79   \n",
            "   3    |   500   |   0.113608   |     -      |     -     |   8.79   \n",
            "   3    |   520   |   0.135486   |     -      |     -     |   8.83   \n",
            "   3    |   540   |   0.118642   |     -      |     -     |   8.80   \n",
            "   3    |   560   |   0.149104   |     -      |     -     |   8.79   \n",
            "   3    |   580   |   0.123654   |     -      |     -     |   8.73   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.125441   |  0.404438  |   87.86   |  263.90  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.091789   |     -      |     -     |   9.24   \n",
            "   4    |   40    |   0.111773   |     -      |     -     |   8.81   \n",
            "   4    |   60    |   0.073390   |     -      |     -     |   8.77   \n",
            "   4    |   80    |   0.062536   |     -      |     -     |   8.73   \n",
            "   4    |   100   |   0.068875   |     -      |     -     |   8.80   \n",
            "   4    |   120   |   0.043974   |     -      |     -     |   8.78   \n",
            "   4    |   140   |   0.054235   |     -      |     -     |   8.77   \n",
            "   4    |   160   |   0.079193   |     -      |     -     |   8.83   \n",
            "   4    |   180   |   0.092797   |     -      |     -     |   8.79   \n",
            "   4    |   200   |   0.090070   |     -      |     -     |   8.77   \n",
            "   4    |   220   |   0.053706   |     -      |     -     |   8.75   \n",
            "   4    |   240   |   0.087206   |     -      |     -     |   8.76   \n",
            "   4    |   260   |   0.063282   |     -      |     -     |   8.78   \n",
            "   4    |   280   |   0.077718   |     -      |     -     |   8.79   \n",
            "   4    |   300   |   0.067770   |     -      |     -     |   8.77   \n",
            "   4    |   320   |   0.041963   |     -      |     -     |   8.78   \n",
            "   4    |   340   |   0.051424   |     -      |     -     |   8.72   \n",
            "   4    |   360   |   0.060484   |     -      |     -     |   8.78   \n",
            "   4    |   380   |   0.116811   |     -      |     -     |   8.79   \n",
            "   4    |   400   |   0.074566   |     -      |     -     |   8.76   \n",
            "   4    |   420   |   0.046701   |     -      |     -     |   8.77   \n",
            "   4    |   440   |   0.067017   |     -      |     -     |   8.80   \n",
            "   4    |   460   |   0.089236   |     -      |     -     |   8.81   \n",
            "   4    |   480   |   0.089287   |     -      |     -     |   8.79   \n",
            "   4    |   500   |   0.075962   |     -      |     -     |   8.80   \n",
            "   4    |   520   |   0.090736   |     -      |     -     |   8.82   \n",
            "   4    |   540   |   0.091643   |     -      |     -     |   8.79   \n",
            "   4    |   560   |   0.054812   |     -      |     -     |   8.79   \n",
            "   4    |   580   |   0.042197   |     -      |     -     |   8.69   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.072831   |  0.511611  |   87.76   |  263.44  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            ">>>>>Training complete! in  0:17:29.648679  secondes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFzFKvdFB8dH"
      },
      "source": [
        "## 3.4. Evaluation sur le jeu de Validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNSzs6ZfCBDH"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # Pour chaque batch ou lot de texte dans notre jeu de test, faire les meme traitement que les précédentes\n",
        "    for batch in test_dataloader:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # utilisation du softmax pour calculer les probabilité\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-TsZo5NunE1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # recupération de la valeur de la précision sur les jeux de test\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Representation ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "tk680d_-CFnD",
        "outputId": "ed002e7b-b780-4776-aff9-d1cebb6c54ea"
      },
      "source": [
        "# prédiction sur le jeux de test\n",
        "probs = bert_predict(bert_classifier, val_discri_dataloader)\n",
        "# evalutaion du classifieur\n",
        "evaluate_roc(probs, y_discri_val)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.9172\n",
            "Accuracy: 87.85%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e8BKYLYwEoRVFCKiBhFUERRFBBEBRE7NnTRtaFr/6msa0NxddeG4uJaQERFLAirNEGRItKLCAJBUQREOiSc3x/nxgwhmUySmbkzyfk8zzzT7tx75iYzZ+77vve8oqo455xzBSkXdgDOOedSmycK55xzUXmicM45F5UnCuecc1F5onDOOReVJwrnnHNReaJwRSIic0XktLDjSBUicq+IvBrStgeJyCNhbDveRORSERldzNf6/2SCeaJIYyLyo4hsEZGNIrIq+OLYK5HbVNXGqjoukdvIISKVROQxEVkevM/vReROEZFkbD+feE4TkczIx1T1UVW9NkHbExG5WUTmiMgmEckUkXdF5JhEbK+4ROQhEXmzJOtQ1bdU9awYtrVbckzm/2RZ5Yki/XVW1b2AZsBxwD0hx1NkIrJHAU+9C5wBdASqAZcDvYBnExCDiEiqfR6eBW4Bbgb2BxoAw4Fz4r2hKH+DhAtz2y5GquqXNL0APwJnRtx/Evgk4v5JwFfA78BM4LSI5/YH/gP8BKwDhkc81wn4LnjdV0DTvNsEDgW2APtHPHcc8BtQIbh/NTA/WP8o4LCIZRW4EfgeWJrPezsD2ArUzvN4CyAbODK4Pw54DJgC/AF8mCemaPtgHPAPYFLwXo4Ergpi3gAsAa4Plq0aLLMT2BhcDgUeAt4MlqkbvK8rgeXBvrgvYnt7Aq8H+2M+8Dcgs4C/bf3gfZ4Y5e8/CHge+CSI9xvgiIjnnwVWBPtlOtA64rmHgGHAm8Hz1wInAl8H++pn4N9AxYjXNAb+B6wFfgHuBdoD24EdwT6ZGSy7DzAwWM9K4BGgfPBcz2CfPwOsCZ7rCUwMnpfguV+D2GYDTbAfCTuC7W0EPsr7OQDKB3H9EOyT6eT5H/JLMb5rwg7ALyX44+36AakVfKCeDe7XDD6EHbEjx3bB/QOC5z8B3gH2AyoAbYLHjws+oC2CD92VwXYq5bPNMcB1EfH0A14KbncBFgMNgT2A+4GvIpbV4Etnf2DPfN7b48D4At73MnK/wMcFX0RNsC/z98j94i5sH4zDvtAbBzFWwH6tHxF8WbUBNgPNg+VPI88XO/knilewpHAssA1oGPmegn1eC5iVd30R670BWFbI339Q8H5ODOJ/CxgS8fxlQPXguT7AKqByRNw7gPOCfbMncDyWWPcI3st84NZg+WrYl34foHJwv0XefRCx7Q+Al4O/yYFYIs/5m/UEsoC/Btvak10TxdnYF/y+wd+hIXBIxHt+JMrn4E7sc3BU8Npjgephf1bT/RJ6AH4pwR/PPiAbsV9OCnwB7Bs8dxfwRp7lR2Ff/Idgv4z3y2edLwJ/z/PYQnITSeSH8lpgTHBbsF+vpwb3RwLXRKyjHPale1hwX4G2Ud7bq5Ffenmem0zwSx37sn884rlG2C/O8tH2QcRr+xayj4cDtwS3TyO2RFEr4vkpQI/g9hLg7Ijnrs27vojn7gMmFxLbIODViPsdgQVRll8HHBsR94RC1n8r8EFw+2JgRgHL/bkPgvsHYQlyz4jHLgbGBrd7AsvzrKMnuYmiLbAIS1rl8nnP0RLFQqBLIj5vZfmSam2yrujOU9Vq2JfY0UCN4PHDgAtF5PecC3AKliRqA2tVdV0+6zsM6JPndbWxZpa83gNaisghwKlY8vkyYj3PRqxjLZZMaka8fkWU9/VbEGt+Dgmez289y7AjgxpE3wf5xiAiHURksoisDZbvSO4+jdWqiNubgZwBBofm2V6097+Ggt9/LNtCRO4Qkfkisj54L/uw63vJ+94biMjHwcCIP4BHI5avjTXnxOIw7G/wc8R+fxk7ssh325FUdQzW7PU88KuIDBCRvWPcdlHidDHyRFFKqOp47NfWU8FDK7Bf0/tGXKqq6uPBc/uLyL75rGoF8I88r6uiqoPz2eY6YDRwEXAJdgSgEeu5Ps969lTVryJXEeUtfQ60EJHakQ+KSAvsy2BMxMORy9TBmlR+K2Qf7BaDiFTCkt9TwEGqui/wKZbgCos3Fj9jTU75xZ3XF0AtEckozoZEpDXWB9IdO3LcF1hP7nuB3d/Pi8ACoL6q7o219ecsvwI4vIDN5V3PCuyIokbEft9bVRtHec2uK1R9TlWPx44QG2BNSoW+Ltj2EYUs44rIE0Xp8k+gnYgci3VSdhaRs0WkvIhUDoZ31lLVn7GmoRdEZD8RqSAipwbreAW4QURaBCOBqorIOSJSrYBtvg1cAXQLbud4CbhHRBoDiMg+InJhrG9EVT/HvizfE5HGwXs4KXhfL6rq9xGLXyYijUSkCtAXGKaq2dH2QQGbrQhUAlYDWSLSAYgcsvkLUF1E9on1feQxFNsn+4lITeCmghYM3t8LwOAg5opB/D1E5O4YtlUN6wdYDewhIv8HFParvBrWebxRRI4G/hLx3MfAISJyazBsuVqQtMH2S92cUWPB/9do4GkR2VtEyonIESLSJoa4EZETgv+/CsAmbFDDzohtFZSwwJos/y4i9YP/36YiUj2W7bqCeaIoRVR1NfBf4P9UdQXWoXwv9mWxAvtVlvM3vxz75b0A67y+NVjHNOA67NB/HdYh3TPKZkdgI3RWqerMiFg+AJ4AhgTNGHOADkV8S12BscBnWF/Mm9hImr/mWe4N7GhqFdbRenMQQ2H7YBequiF47VDsvV8SvL+c5xcAg4ElQZNKfs1x0fQFMoGl2BHTMOyXd0FuJrcJ5nesSeV84KMYtjUK22+LsOa4rURv6gK4A3vPG7AfDO/kPBHsm3ZAZ2w/fw+cHjz9bnC9RkS+DW5fgSXeedi+HEZsTWlgCe2V4HXLsGa4fsFzA4FGwf4fns9r+2N/v9FY0huIdZa7EpDclgLn0o+IjMM6UkM5O7okROQvWEd3TL+0nQuLH1E4lyQicoiInBw0xRyFDTX9IOy4nCtMwhKFiLwmIr+KyJwCnhcReU5EFovILBFpnqhYnEsRFbHRPxuwzvgPsX4I51Jawpqegs7RjcB/VbVJPs93xNqaO2Indz2rqi3yLueccy5cCTuiUNUJ2Nj5gnTBkoiq6mRg32A8vnPOuRQSZjGumuw6CiMzeOznvAuKSC+szgtVq1Y9/uijj05KgM650k0VtmyJvsz69bB9++6P7diRuLjiqQ7L2JffmUXWb6p6QHHWkRZVG1V1ADAAICMjQ6dNmxZyRM65RFu9Gj78EHYGZ1D873+weDGULx+/bXz7beHL5DjooNzbe+8Na9fCxx9D06bxiyducroURKj63xcpt+ZX9u3/0LLiri7MRLGSXc9MrRU85pxLcz/8AE8+mft9lZ/PP4elS4u+7nPiWGT9nHOgUiW48sroy7VosWuiSGkrV0Lvv8BFF8Gll8K9wXmT/R8q9irDTBQjgJtEZAjWmb0+OKPTOZdGNm2CoUNhW3Dq4Nixdj/HIQX0PGZngwjcfz+UK6C39KCDoEuX3Pv77Qd7+ulz+VOFV1+FO+6wdrE4ZtSEJQoRGYwVqqshNivYg1ihMFT1JayGTkfszN/N2DwAzrkUsXEjzJu3++Nr1sBbb0HlyjBokH3h56d/f/jLX2w5l2A//ADXXWdZ+vTT4ZVX4Ij4lbxKWKJQ1YsLeV6xiWucc8WQlRW9aScW/frBkCH2yz6vWbOiv7ZcOTjwQIvhttvgiity17PXXnZxSTJ7NkyfDgMGwLXX5v8HLYG06Mx2riz7+Wf48cddH7vzTpg0KX7bOO+83R87/HBr6unWbffn9tsPWraM3/ZdMcyZY73xV1xhf8AlS6B6YuofeqJwLol27LBRPOPHw8KFuY8//bT9As/vh+CcfGsbmAcesM7YkjjrLDjhhJKtwyXR9u3w6KN2Oegg6N7d2vcSlCTAE4Vz+dq+3X6sFdT+PnUqTJtWtKGa06bl3+Yf6YILdn/syCOhcWNo3XrXx084AfbfP/btu1Lgm2/gmmtg7ly47DJ45pmkdAJ5onClhips3Rp9mXXr4L33csfm5/X227BhA8yfH9s269aNPb6dO+0zffvtULWq/ZKvV8+eK1fOmnOcK9DKlfZr4aCD7ASOeI4TLoQnClcq7Nxpv67Xr4/P+nLa5Xv1KniZww+P68AS5/K3aBE0aAA1a8I778AZZ9gZf0nkicKltOxsO0qYPRu++grefNPG7ecdd79gQe7txx8nqv33z7+DNsfee8f37F/niuX33+Fvf7NzI8aNg1NPhfPPDyUUTxQu5WzZYn0AmZl2Yml+unff9X7TprB5M7zxBuyb30zgzqWTESPsJJRVq2yIW8ijDTxRuJSwfbs1u/buDb/8sutzxxwDl18Oxx1nn5dq1Qo+k9e5tHfttTBwoP3jf/ghZGSEHZEnCpdcP/1kTUivv24dumBNSR9/nLvMmWdC7dqWHGrUsM+Lc6VaRBE/MjLgsMPgrrugYsVw4wp4onBJsWGDnRc0fHjuY5Ur2+dh506oUwdOOcWamjp2DC9O55JuxQq44Qbo0cN+Hd1wQ9gR7cYThSuWrVvh66+tpExWVvRlP/vMEkWOBx+0E0mPPTbulQacSx87d8LLL9uRQ3Z2aB3VsfBE4QD7sv/jj9z748bB3Xdb30F+/QF5y0M3bFjwumvWtEJy994LXbtas5JzZdr331tfxIQJ1tY6YEDuSTUpyBNFGZWVZX0FGzbAc8/B6NEFL3v55bs/dsoplkB69YLmzb1CqHNFMm+eVV187TXo2TPlD609UZQhmzfbZft2+5WfV+vWuecXqEK7dnakkOL/w86lh5kz4bvvbJakLl2siF+anI7viaIMGDnS5gb4/PPdn5swwUYfNWvmQ06dS4ht2+CRR+xM0EMOsZnnKldOmyQBnihKrYkTYcwYOxoYOtQqlR5xhM1pcuyxUKWKNSlVqBB2pM6VYl9/bUX85s+3YX/9+6dlO60nilJmwQKb7KpTp10f79zZTvZ0ziXJypXQpg0cfDB8+il06BB2RMXmjQ2lxFtvWVHJhg1zk8TFF1undVaWneDpnEuCnNLDNWva4fzcuWmdJMCPKNJaVhZ88IGVpd++3R674gobkdS8udU/8uJ2ziXJunXQpw/85z/W+de6df5TB6YhTxRp6uef7XyEyIl1RoywJibnXJJ98IEVKlu9Gu65J/QifvHmiSJNqNqPlCFDYNkyG8mUY9686Ce8OecS6Oqr7SiiWTP45BM7nC9lPFGksM8+s9FLIvDuu7vOsXz88TZxzpAhPqzVuaSLLOJ30klQvz7ccUepHUboiSIFqdp8C8OG2f1y5XKn7hw50v4vfc4F50KybBlcfz1ccol1CkabBrGU8N+iIdu+HX780QrliVgCqFo1N0l89JH1Q6japX17TxLOhWLnTnj+eWjSxA71d+wIO6Kk8SOKED36KNx3366PHXWU9YPtsQfceivUrRtKaM65SAsXWhG/iRPhrLOs6msZ+nB6okiyN9+EOXNsop65c+2xDh3snIfOnf1owbmUtHChfWAHDbLmpjJWAM0TRRI8/DCMH299DV98setzU6emxEyHzrm8ZsywIn5XXQXnnmtF/MroLznvo0ig336zgRAPPQRjx9pkP61bW7LI6XPwJOFcitm61SZPOeEE+/Bu3WqPl9EkAX5EEXeXXAKrVtntsWNzHx882GY6dM6lsEmTrIjfwoV2JPH002lZxC/ePFHEyejR1teQM4y1dWsrpXHQQfD22ykzR7pzriArV1p55Zo1YdQo67R2gCeKuOnTx5LE9dfb0erBB4cdkXMuJvPmQaNGliDee8+SxV57hR1VSvE+ijjYssVGMgG88IInCefSwtq1Ng1p48ZWHwds6KEnid34EUUc5Mw33bOnl9NwLi289x7ceCOsWWMnM514YtgRpTRPFCW0fXtuJeGbbgo3FudcDHr2hNdft+J9n31mxfxcVJ4oSiiyiqv/vzmXoiKL+LVqZeWW+/SxEgiuUAltKBGR9iKyUEQWi8jd+TxfR0TGisgMEZklIh0TGU8i/Pe/dv3NNz5JkHMpaelSG8GU82Ht1QvuusuTRBEkLFGISHngeaAD0Ai4WEQa5VnsfmCoqh4H9ABeSFQ8iTJlCuy3nzdxOpdysrPhueesiN/kyblHFa7IEnlEcSKwWFWXqOp2YAjQJc8yCuwd3N4H+CmB8cTduHGQmbnrLHPOuRQwf76dzHTLLdCmjdVp6tkz7KjSViKPvWoCKyLuZwIt8izzEDBaRP4KVAXOzG9FItIL6AVQp06duAdaHCefDF99Zbefey7cWJxzeSxebGdXv/EGXHppmSviF29hD+a8GBikqrWAjsAbIrJbTKo6QFUzVDXjgAMOSHqQu8ZiZ/bnJIm337Ziks65kE2fDq+9Zrc7d7a+icsu8yQRB4lMFCuB2hH3awWPRboGGAqgql8DlYEaCYyp2DZtgsces/MkBg2yx2bOtPLg/n/oXIi2bIG774YWLeDvf88t4rf33tFf52KWyKanqUB9EamHJYgewCV5llkOnAEMEpGGWKJYncCYiiU7e9eTNWvXhi+/hMMOCy8m5xx2RvW118L331sxv6ee8iJ+CZCwIwpVzQJuAkYB87HRTXNFpK+InBss1ge4TkRmAoOBnqqpNTRh+HCbmhSgWjVYtw6WL/ck4VzoVq6EM86ArCz4/HN49dUyXQo8kSTFvpcLlZGRodOmTUvKtjZtsiMJEWjbFt56y6rBOudCNHs2HHOM3f74Yyvil/NrzhVIRKararFmwAm7Mzul5YxmatDAfrB4knAuRL/9BpdfDk2b5hbx69TJk0QS+KmJUTzxhF2/9164cThXpqnCu+9aMbV16+DBB63j2iWNJ4oCfPUVrF9vs9I1bhx2NM6VYVdeaedDZGTYPMI5zU4uaTxR5GPTJjuhDuDYY8ONxbkyKbKIX5s21tx0661enykk3keRx0UX5Q6F7dTJhmc755JoyRI488zcE5auuQbuuMOTRIg8UeQxdKhd9+yZW2zSOZcE2dnwz39a09LUqT4LWArxFJ2P++6DRx4JOwrnypB58+Dqq61e/znnwEsvQa1aYUflAp4oImzYYNdeksO5JFu6FH74wYqn9ejhH8IU44kiwiVBgZFKlcKNw7kyYepU+O47uO46O4pYssTKH7iU442AgexsO8kTrN/MOZcgmzfbh+ykk6zSZk4RP08SKavMJ4qdO2HtWmjf3u536uQ1xZxLmHHjbKjr00/bkcSMGf6BSwNlvumpY0cYNSr3/osvhheLc6VaZia0a2cVNceMsRpNLi2U6SOKceNyk8Tzz8Mff/hAC+fibuZMu65VCz78EGbN8iSRZsp0orjpJrseMgR69/YmUufiavVqGyHSrBmMH2+PdewIVaqEG5crsjLb9PT44zbf+gUX2NnYzrk4UbVfXzffbAXTHn4YWrYMOypXAmU2UeScdZ1zVOGci5PLL7fJW1q0gIEDvapmKRBzohCRKqq6OZHBJNP8+XD44d5U6lxc7NxpJ8mJ2Ifq+OPtiKJ8+bAjc3FQaB+FiLQSkXnAguD+sSLyQsIjS6B33rHrnAqxzrkSWLzYpiT9z3/s/jXXwG23eZIoRWLpzH4GOBtYA6CqM4FTExlUouVMRHTXXeHG4Vxay8qCp56yIn4zZkDFimFH5BIkpqYnVV0hu9ZeyU5MOMmx775QoYI3nTpXbHPmwFVXwbRp0KULvPACHHpo2FG5BIklUawQkVaAikgF4BZgfmLDSpzsbJuYqEaNsCNxLo0tXw7Lltnopu7dvYhfKRdL09MNwI1ATWAl0AzoncigEumGG6xApR8lO1dE33wDAwbY7Y4drYjfRRd5kigDYkkUR6nqpap6kKoeqKqXAQ0THVgiqMKrr9oJokOGhB2Nc2li0ya4/XY7F+LJJ2HbNns8ZypIV+rFkij+FeNjKe+00+y6dm0rXOmcK8SYMVbE75ln7HD822+9Dn8ZVGAfhYi0BFoBB4jI7RFP7Q2k3bi3bdtgwgS7/f774cbiXFrIzISzz4Z69awEx6lpPdjRlUC0zuyKwF7BMpFVkP4AuiUyqETIGeJ93nlw8MHhxuJcSpsxA447ztpoP/oI2rSBPfcMOyoXogIThaqOB8aLyCBVXZbEmBLizTft+rnnwo3DuZT1yy92NvXQoVZauU2b3IlaXJkWy/DYzSLSD2gM/DnDiKq2TVhUcdavH0yaZLd9qLdzeahabaZbboGNG+GRR6BVq7Cjcikkls7st7DyHfWAh4EfgakJjCmuVqyAv/3Nbn/0kVcVcG43l1xihfyOOsrmsL7vPjsj1blALEcU1VV1oIjcEtEclTaJYvlyu37iCZvm1DnHrkX8zjrLhr7eeKP/knL5iuWIYkdw/bOInCMixwH7JzCmuHr5Zbs+/vhw43AuZSxaZBVeX3vN7l91lVd6dVHFckTxiIjsA/TBzp/YG7g1oVHF0eagMLqfN+HKvKws6N8fHnwQKlf2kUwuZoUmClX9OLi5HjgdQETSqkB348ZQtWrYUTgXolmz4OqrYfp0OP98myT+kEPCjsqliWgn3JUHumM1nj5T1Tki0gm4F9gTOC45IZbMokU2qMO5Mi0z00Z2vPsudO3q9ZlckUTroxgIXAtUB54TkTeBp4AnVTWmJCEi7UVkoYgsFpG7C1imu4jME5G5IvJ2Ud9AYWbPhp9+ivdanUsDX30FL71kt3OK+HXr5knCFVm0pqcMoKmq7hSRysAq4AhVXRPLioMjkueBdkAmMFVERqjqvIhl6gP3ACer6joRObC4byQ/OTPZtWsXz7U6l+I2brQhrv/6FxxxhHVWV6rk7a+u2KIdUWxX1Z0AqroVWBJrkgicCCxW1SWquh0YAnTJs8x1wPOqui7Yzq9FWH+hHn/crh94IJ5rdS6FjR4NTZpYkrjxRi/i5+Ii2hHF0SIyK7gtwBHBfQFUVZsWsu6awIqI+5lAizzLNAAQkUlYocGHVPWzvCsSkV5AL4A6deoUstlcOXNOHHNMzC9xLn2tWAHnnGNHERMmwCmnhB2RKyWiJYpkzDmxB1AfOA2oBUwQkWNU9ffIhVR1ADAAICMjI+au6fLlvdnJlQHTp9uJQrVrw6efQuvWNvzVuTgpsOlJVZdFu8Sw7pVA7Yj7tYLHImUCI1R1h6ouBRZhiaPE1q2Dr7/2EU+uFFu1Ci68EDIyrAw42C8jTxIuzmI5M7u4pgL1RaSeiFQEegAj8iwzHDuaQERqYE1RS+Kx8UWL7Pqww+KxNudSiCq8/jo0amQFzB591Iv4uYSK5czsYlHVLBG5CRiF9T+8pqpzRaQvME1VRwTPnSUi84Bs4M4idpgX6I8/7Lpr13iszbkU0qOHlQI/+WSb2/foo8OOyJVyojG0zYjInkAdVV2Y+JCiy8jI0GnTpkVdZu1aqF7dbk+a5D+2XCkQWcTv9ddhwwbo3RvKJbJRwJUmIjJdVTOK89pC/8tEpDPwHfBZcL+ZiORtQkopOVOeVqjgScKVAgsW2DSkAwfa/SuvhJtu8iThkiaW/7SHsHMifgdQ1e+wuSlSVs5B0tS0KYbuXD527LD+h2OPhXnzYK+9wo7IlVGx9FHsUNX1sutp/yk9lmjKlLAjcK6EvvvOzqj+7jsru/Gvf/lk7y40sSSKuSJyCVA+KLlxM/BVYsMqmZ077fqoo8KNw7liW7XKLu+9BxdcEHY0royLpenpr9h82duAt7Fy4yk/H0Xlyj6c3KWZiRPhhRfsdvv28MMPniRcSoglURytqvep6gnB5f6g9pNzLh42bLDO6dat4Z//hG3b7PEqVcKNy7lALIniaRGZLyJ/F5EmCY8oDkaNyv2sOZfSRo2yIn4vvAC33OJF/FxKKjRRqOrp2Mx2q4GXRWS2iNyf8MhKoFo1L93h0sCKFdCpkx05TJxoRxM+ssmloJgGYqvqKlV9DrgBO6fi/xIaVQksXWqfudNOCzsS5/Khmjssr3ZtGDkSZszwE35cSovlhLuGIvKQiMwG/oWNeKqV8MiKqUcPuz4uLSZqdWXKzz9bTZkWLXKL+J15po+6cCkvluGxrwHvAGeraspPKvprMPXRE0+EG4dzf1KFQYPg9tth61b75zz55LCjci5mhSYKVW2ZjEDipXx5uPRSK9/hXEro3h2GDbNRTa++Cg0ahB2Rc0VSYKIQkaGq2j1ocorsGo51hrtQZGWFHYFzQHa2FfArVw46d4a2beH6670+k0tL0Y4obgmuOyUjkHjYvBmWLbN5XJwLzfz5cM01VoLjuuvgiivCjsi5Eok2w93Pwc3e+cxu1zs54RXNuHF2feCBoYbhyqodO+CRR6BZM1i4EPbZJ+yInIuLWI6D85t1ukO8A4mHmTPtumfPUMNwZdGMGXYo+8ADcP75dlTRvXvYUTkXF9H6KP6CHTkcLiKzIp6qBkxKdGDFMXSoXdePy6zbzhXBL7/Ab7/B8OHQpUvY0TgXV9H6KN4GRgKPAXdHPL5BVdcmNKpi2m+/Xa+dS6gJE2D2bLjxRivit3gx7Lln2FE5F3fRmp5UVX8EbgQ2RFwQkf0TH1rxtG4ddgSu1PvjD5uGtE0beO653MJiniRcKVXYEUUnYDo2PDZy5iIFDk9gXM6lpk8/tWGuP/1kJ9D17etF/FypV2CiUNVOwXVKT3vqXNKsWGH9D0cdZSfQtWgRdkTOJUUstZ5OFpGqwe3LRKS/iNRJfGjOpQBVmDzZbteuDaNHWylwTxKuDIlleOyLwGYRORboA/wAvJHQqJxLBT/9BOedBy1b5hbxO/10qFgx3LicS7JYEkWWqirQBfi3qj6PDZFNKdu2wZdf+jwULg5UrSZTo0Z2BPHUU17Ez5VpsVSP3SAi9wCXA61FpByQciX3hg61Ok97xPKOnIumWzd4/30b1fTqq3DkkWFH5FyoYjmiuAjYBlytqquwuSj6JTSqYsiZk37AgHDjcGkqOxt27rTb550HL70EY8Z4knCO2F+HxdMAABpnSURBVKZCXQW8BewjIp2Arar634RHVkRr1th1PR+j5YpqzhxrWho40O5ffrlXenUuQiyjnroDU4ALge7ANyLSLdGBFVW5cnDRRd705Ipg+3Z4+GFo3hx++MFP6XeuALF8rd4HnKCqvwKIyAHA58CwRAbmXEJNn27VI+fMgUsugX/+Ew44IOyonEtJsSSKcjlJIrCG2Po2nEtda9bA77/DRx9Bp7SZcsW5UMSSKD4TkVHA4OD+RcCniQup6L7/3sr/H3NM2JG4lDZ2rBXxu/lmOOss+8epXDnsqJxLebF0Zt8JvAw0DS4DVPWuRAdWFO+9Z9ennBJuHC5FrV9vndNt28KLL+YW8fMk4VxMos1HUR94CjgCmA3coaorkxVYrLKz4Ykn7LZPWOR289FHcMMNsGoV3HGHdV57ET/niiTaEcVrwMdAV6yC7L+SElERzZ5tTc3gM0+6PFasgK5doXp1q9fUrx9UqRJ2VM6lnWh9FNVU9ZXg9kIR+TYZARXVI4/Y9QcfhBuHSxGq8PXX0KpVbhG/Vq28PpNzJRDtiKKyiBwnIs1FpDmwZ577hRKR9iKyUEQWi8jdUZbrKiIqIhlFfQNTp9q1zz7pyMyEc8+1k+dyividdponCedKKNoRxc9A/4j7qyLuK9A22opFpDzwPNAOyASmisgIVZ2XZ7lqwC3AN0UL3VSrBlWrgkjhy7pSaudOeOUVuPNOK/jVv7+PbHAujqJNXHR6Cdd9IrBYVZcAiMgQrALtvDzL/R14ArizOBsRgbPPLkmYLu117QrDh9uopldegcN98kXn4imRJ87VBFZE3M8MHvtT0IRVW1U/ibYiEeklItNEZNrq1avjH6lLP1lZuUX8una1BPH5554knEuA0M6wDsqV98cmQ4pKVQeoaoaqZhzgZRbcrFk2mdArwViLyy6Da6/19kfnEiSRiWIlUDvifq3gsRzVgCbAOBH5ETgJGFGcDm1XRmzbBg8+CMcfD8uWeW0m55IkluqxEsyV/X/B/ToicmIM654K1BeReiJSEegBjMh5UlXXq2oNVa2rqnWBycC5qjqtWO/ElW5Tp1qV17594eKLYf58uOCCsKNyrkyI5YjiBaAlcHFwfwM2mikqVc0CbgJGAfOBoao6V0T6isi5xYzXlVXr1sHGjfDpp/Df/9pJdM65pIilKGALVW0uIjMAVHVdcIRQKFX9lDwFBFX1/wpY9rRY1hkpK8uqRDdoUNRXurQwZoyden/LLVbEb9EiL7/hXAhiOaLYEZwTofDnfBQ7ExpVjL76yq5zary5UuL33+G66+CMM+Dll3P/wJ4knAtFLIniOeAD4EAR+QcwEXg0oVHFaPt2u/7b38KNw8XRhx9Co0bw2mv2h50+3ROEcyErtOlJVd8SkenAGYAA56nq/IRHFoOsLLv2qY1LieXL4cILoWFDGDECMnwAnHOpoNBEISJ1gM3AR5GPqeryRAYWizFj7NoLgqYxVZg4EVq3hjp17KS5k07y+kzOpZBYOrM/wfonBKgM1AMWAo0TGFdMqlWz66ZNw43DFdPy5TZXxMiRMG4ctGkDp54adlTOuTxiaXraZYLRoOxG74RFVAx+Qm6a2bkTXnoJ7rrLjiiee86L+DmXwmI5otiFqn4rIi0SEYwrIy64wDqt27WDAQOgbt2wI3LORRFLH8XtEXfLAc2BnxIWURF8/nnYEbiYZWXZqINy5eCii2wCkZ49/XDQuTQQy3ihahGXSlifRUpME7TXXnZdvny4cbhCzJwJLVrY0QNYCY6rrvIk4VyaiHpEEZxoV01V70hSPEXmIyhT2NatNlftE0/A/vvDwQeHHZFzrhgKTBQisoeqZonIyckMyJUSU6bAlVfCggV23b+/JQvnXNqJdkQxBeuP+E5ERgDvAptynlTV9xMcW6E+/dQqTrsU9McfsGULfPaZT0HoXJqLZdRTZWANNkd2zvkUCoSeKPbaC3bsCDsK96fRo2HuXLjtNjjzTFi40MtvOFcKREsUBwYjnuaQmyByaEKjilGFCnaOlgvZunVw++0waBA0bgy9e1uC8CThXKkQbdRTeWCv4FIt4nbOxTl4/30r4vfGG3DPPTBtmicI50qZaEcUP6tq36RF4tLP8uXQowc0aWIdRscdF3ZEzrkEiHZE4YPc3e5UYfx4u12njlVm/OYbTxLOlWLREsUZSYuiGFStadwl0bJl0KEDnHZabrI45RTrLHLOlVoFJgpVXZvMQIpq6VK73rAh3DjKhJ074d//to7qiRPhX/+ysuDOuTKhyEUBU8Xs2XZ9Rkof95QS550HH31k50O8/DIcdljYETnnkihtE8VTT9l1w4bhxlFq7dhhRbTKlbPaTN26weWXe30m58qgtJ1EdMUKu/YzsxPg22/hxBNtzgiwRHHFFZ4knCuj0jZRrF8PrVqFHUUps2WLnQtx4omwahXUrh12RM65FJCWTU8bN8Lvv1sfq4uTyZOteN+iRXD11da2t99+YUflnEsBaZkopk+3a+/IjqNNm6xf4n//szpNzjkXSMtEkZlp1/59VkKffWZF/Pr0say7YAFUrBh2VM65FJOWfRQ//GDXPg9OMa1ZY81MHTrA66/D9u32uCcJ51w+0jJRzJ9v1/XqhRtH2lGFYcOsiN/bb8P998PUqZ4gnHNRpWXT0/r1du2VI4po+XK45BJo2tTmjjj22LAjcs6lgbQ8oqhQAZo1s3PBXCFUrXAf2BnV48bZCCdPEs65GPlXbWm2dCmcdZZ1VOcU8WvVCvZIywNJ51xI0jJRbNpkP5RdAbKz4dlnbZ6Ib76BF1/0In7OuWJLy5+WX3wBRx4ZdhQprEsX+OQT6NjRynD4GdbOuRJIy0Sx//5Qt27YUaSYyCJ+l19u9ZkuucTrMznnSiyhTU8i0l5EForIYhG5O5/nbxeReSIyS0S+EJGY6levXetHFLuYNg0yMqyJCeCii+DSSz1JOOfiImGJQkTKA88DHYBGwMUi0ijPYjOADFVtCgwDnixsvTt22PWaNfGMNk1t2QJ33QUtWsDq1T5PhHMuIRJ5RHEisFhVl6jqdmAI0CVyAVUdq6qbg7uTgVqFrTSnEGCHDnGNNf18/bUNcX3ySSviN28edOoUdlTOuVIokX0UNYEVEfczgRZRlr8GGJnfEyLSC+gFcOihdjp2+fJxiTF9bdliWfPzz706onMuoVKiM1tELgMygDb5Pa+qA4ABAEcdlaH2WNLCSx2ffmpF/O68E9q2tVomfnq6cy7BEtn0tBKIHJdZK3hsFyJyJnAfcK6qbitspTn168pUQcDffoPLLoNzzoG33srdCZ4knHNJkMhEMRWoLyL1RKQi0AMYEbmAiBwHvIwliV9jWekff9h1o7zd4qWRKgwZYhODDx0KDz4IU6Z4ET/nXFIlrOlJVbNE5CZgFFAeeE1V54pIX2Caqo4A+gF7Ae+KDeVcrqrnRltvTt9EmTiHbPlyKwd+7LEwcCAcc0zYETnnyiDRNGvsr1IlQytUmPZnBdlSR9VOPc+ZlWnyZDjhBO+9d86ViIhMV9WM4rw27Wo9bdmS2/xU6vzwg41gatcut4jfSSd5knDOhSrtEgXAPfeEHUGcZWdD//7WtDR9Orz8shfxc86ljJQYHltUVaqEHUGcde4MI0faCXMvvgi1Cj3v0DnnkiYtE0WpsH27zQtRrhz07GmF/Hr08PpMzrmUk5ZNT5s3F75MSpsyBY4/Hl54we53727VXj1JOOdSUFomirZtw46gmDZvhj59oGVLWLcOjjgi7Iicc65Q3vSULBMn2jkRS5bA9dfDE0/APvuEHZVzzhXKE0Wy5EwsNHYsnHZa2NE451zMPFEk0kcfWeG+v/0NTj/dSoHv4bvcOZde0rKPIuWtXm3TkJ57LgwenFvEz5OEcy4NeaKIJ1V4+20r4jdsGPTtC99840X8nHNpzX/ixtPy5XDVVXDccVbEr3HjsCNyzrkS8yOKktq5E0aNstuHHQZffgmTJnmScM6VGp4oSuL77+2kjvbtYcIEe+zEE72In3OuVPFEURxZWdCvHzRtCt99Z81MXsTPOVdKeR9FcXTqZM1NXbpYGY5DDw07IudS0o4dO8jMzGTr1q1hh1JmVK5cmVq1alEhjlMle6KI1bZtNkd1uXJw7bVw9dVw4YVen8m5KDIzM6lWrRp169ZF/LOScKrKmjVryMzMpF69enFbrzc9xWLyZGjeHJ5/3u5362aF/Pwf37motm7dSvXq1T1JJImIUL169bgfwXmiiGbTJrjtNmjVCjZsgPr1w47IubTjSSK5ErG/vempIF9+aUX8li6F3r3hscdg773Djso555IuLY8oqldPwkaysqxPYvx4a3LyJOFc2ho+fDgiwoIFC/58bNy4cXTq1GmX5Xr27MmwYcMA64i/++67qV+/Ps2bN6dly5aMHDmyxLE89thjHHnkkRx11FGMyjkHK48xY8bQvHlzmjRpwpVXXklWVhYAb731Fk2bNuWYY46hVatWzJw5s8TxxCItE0XCWoCGD7cjB7AifnPnwqmnJmhjzrlkGTx4MKeccgqDBw+O+TUPPPAAP//8M3PmzOHbb79l+PDhbNiwoURxzJs3jyFDhjB37lw+++wzevfuTXZ29i7L7Ny5kyuvvJIhQ4YwZ84cDjvsMF5//XUA6tWrx/jx45k9ezYPPPAAvXr1KlE8sfKmJ4BffoG//hXefdc6rfv0sfpMXsTPubi59VY77SiemjWDf/4z+jIbN25k4sSJjB07ls6dO/Pwww8Xut7NmzfzyiuvsHTpUipVqgTAQQcdRPfu3UsU74cffkiPHj2oVKkS9erV48gjj2TKlCm0bNnyz2XWrFlDxYoVadCgAQDt2rXjscce45prrqFVq1Z/LnfSSSeRmZlZonhilZZHFHGjCm+8AY0awYcfwj/+YSOcvIifc6XGhx9+SPv27WnQoAHVq1dn+vTphb5m8eLF1KlTh71jaHK+7bbbaNas2W6Xxx9/fLdlV65cSe3atf+8X6tWLVauXLnLMjVq1CArK4tp06YBMGzYMFasWLHbugYOHEiHDh0KjS8eyvZP5uXL7ZyIjAw7u/roo8OOyLlSq7Bf/okyePBgbrnlFgB69OjB4MGDOf744wscHVTUUUPPPPNMiWPMu/0hQ4Zw2223sW3bNs466yzK5ykLNHbsWAYOHMjEiRPjuu2ClL1EkVPEr0MHK+I3aZJVe/X6TM6VOmvXrmXMmDHMnj0bESE7OxsRoV+/flSvXp1169bttnyNGjU48sgjWb58OX/88UehRxW33XYbY8eO3e3xHj16cPfdd+/yWM2aNXc5OsjMzKRmzZq7vbZly5Z8+eWXAIwePZpFixb9+dysWbO49tprGTlyJNWTMrIHO5MvnS5wvG7YoMWzcKFq69aqoDpuXDFX4pyL1bx580Ld/ssvv6y9evXa5bFTTz1Vx48fr1u3btW6dev+GeOPP/6oderU0d9//11VVe+8807t2bOnbtu2TVVVf/31Vx06dGiJ4pkzZ442bdpUt27dqkuWLNF69eppVlbWbsv98ssvqqq6detWbdu2rX7xxReqqrps2TI94ogjdNKkSVG3k99+B6ZpMb93y0YfRVYWPPGEFfGbPRv+8x8fzeRcGTB48GDOP//8XR7r2rUrgwcPplKlSrz55ptcddVVNGvWjG7duvHqq6+yzz77APDII49wwAEH0KhRI5o0aUKnTp1i6rOIpnHjxnTv3p1GjRrRvn17nn/++T+blTp27MhPP/0EQL9+/WjYsCFNmzalc+fOtG3bFoC+ffuyZs0aevfuTbNmzcjIyChRPLESSzTpQyRDd+yYVrQBSWefDaNHwwUX2DkRBx+csPicc7nmz59Pw4YNww6jzMlvv4vIdFUtVmZJuz6KypVjHLW6daudMFe+PPTqZZeuXRMen3POlTals+lp0iQbYJ1TxK9rV08SzjlXTKUrUWzcCDffbJMIbd0KfsjrXOjSrXk73SVif5eeRDF+PDRpAv/+N9x0E8yZA+3ahR2Vc2Va5cqVWbNmjSeLJNFgPorKlSvHdb1p10cRVZUqVvX15JPDjsQ5h515nJmZyerVq8MOpczImeEuntJu1NOee2boli12ajvvvw8LFsC999r97Gw/cc455/JRklFPCW16EpH2IrJQRBaLyN35PF9JRN4Jnv9GROrGtOJVq2yWua5d4YMPYPt2e9yThHPOxV3CEoWIlAeeBzoAjYCLRaRRnsWuAdap6pHAM8ATha133+w11kn98cdWEvyrr7yIn3POJVAijyhOBBar6hJV3Q4MAbrkWaYL8HpwexhwhhRSkevQHcus03rmTLj7bjtXwjnnXMIksjO7JhBZGzcTaFHQMqqaJSLrgerAb5ELiUgvIGeGjm0yceIcr/QKQA3y7KsyzPdFLt8XuXxf5DqquC9Mi1FPqjoAGAAgItOK2yFT2vi+yOX7Ipfvi1y+L3KJyLTivjaRTU8rgdoR92sFj+W7jIjsAewDrElgTM4554ookYliKlBfROqJSEWgBzAizzIjgCuD292AMZpu43Wdc66US1jTU9DncBMwCigPvKaqc0WkL1YXfQQwEHhDRBYDa7FkUpgBiYo5Dfm+yOX7Ipfvi1y+L3IVe1+k3Ql3zjnnkqv01HpyzjmXEJ4onHPORZWyiSJh5T/SUAz74nYRmScis0TkCxE5LIw4k6GwfRGxXFcRUREptUMjY9kXItI9+N+YKyJvJzvGZInhM1JHRMaKyIzgc9IxjDgTTUReE5FfRWROAc+LiDwX7KdZItI8phUXd7LtRF6wzu8fgMOBisBMoFGeZXoDLwW3ewDvhB13iPvidKBKcPsvZXlfBMtVAyYAk4GMsOMO8f+iPjAD2C+4f2DYcYe4LwYAfwluNwJ+DDvuBO2LU4HmwJwCnu8IjAQEOAn4Jpb1puoRRULKf6SpQveFqo5V1c3B3cnYOSulUSz/FwB/x+qGbU1mcEkWy764DnheVdcBqOqvSY4xWWLZFwrsHdzeB/gpifEljapOwEaQFqQL8F81k4F9ReSQwtabqokiv/IfNQtaRlWzgJzyH6VNLPsi0jXYL4bSqNB9ERxK11bVT5IZWAhi+b9oADQQkUkiMllE2ictuuSKZV88BFwmIpnAp8BfkxNayinq9wmQJiU8XGxE5DIgA2gTdixhEJFyQH+gZ8ihpIo9sOan07CjzAkicoyq/h5qVOG4GBikqk+LSEvs/K0mqroz7MDSQaoeUXj5j1yx7AtE5EzgPuBcVd2WpNiSrbB9UQ1oAowTkR+xNtgRpbRDO5b/i0xghKruUNWlwCIscZQ2seyLa4ChAKr6NVAZKxhY1sT0fZJXqiYKL/+Rq9B9ISLHAS9jSaK0tkNDIftCVderag1VrauqdbH+mnNVtdjF0FJYLJ+R4djRBCJSA2uKWpLMIJMkln2xHDgDQEQaYomiLM7POgK4Ihj9dBKwXlV/LuxFKdn0pIkr/5F2YtwX/YC9gHeD/vzlqnpuaEEnSIz7okyIcV+MAs4SkXlANnCnqpa6o+4Y90Uf4BURuQ3r2O5ZGn9Yishg7MdBjaA/5kGgAoCqvoT1z3QEFgObgatiWm8p3FfOOefiKFWbnpxzzqUITxTOOeei8kThnHMuKk8UzjnnovJE4ZxzLipPFC4liUi2iHwXcakbZdmNcdjeIBFZGmzr2+Ds3aKu41URaRTcvjfPc1+VNMZgPTn7ZY6IfCQi+xayfLPSWinVJY8Pj3UpSUQ2qupe8V42yjoGAR+r6jAROQt4SlWblmB9JY6psPWKyOvAIlX9R5Tle2IVdG+Kdyyu7PAjCpcWRGSvYK6Nb0VktojsVjVWRA4RkQkRv7hbB4+fJSJfB699V0QK+wKfABwZvPb2YF1zROTW4LGqIvKJiMwMHr8oeHyciGSIyOPAnkEcbwXPbQyuh4jIORExDxKRbiJSXkT6icjUYJ6A62PYLV8TFHQTkROD9zhDRL4SkaOCs5T7AhcFsVwUxP6aiEwJls2v+q5zuwq7frpf/JLfBTuT+Lvg8gFWRWDv4Lka2JmlOUfEG4PrPsB9we3yWO2nGtgXf9Xg8buA/8tne4OAbsHtC4FvgOOB2UBV7Mz3ucBxQFfglYjX7hNcjyOY/yInpohlcmI8H3g9uF0Rq+S5J9ALuD94vBIwDaiXT5wbI97fu0D74P7ewB7B7TOB94LbPYF/R7z+UeCy4Pa+WP2nqmH/vf2S2peULOHhHLBFVZvl3BGRCsCjInIqsBP7JX0QsCriNVOB14Jlh6vqdyLSBpuoZlJQ3qQi9ks8P/1E5H6sBtA1WG2gD1R1UxDD+0Br4DPgaRF5Amuu+rII72sk8KyIVALaAxNUdUvQ3NVURLoFy+2DFfBbmuf1e4rId8H7nw/8L2L510WkPlaiokIB2z8LOFdE7gjuVwbqBOtyLl+eKFy6uBQ4ADheVXeIVYetHLmAqk4IEsk5wCAR6Q+sA/6nqhfHsI07VXVYzh0ROSO/hVR1kdi8Fx2BR0TkC1XtG8ubUNWtIjIOOBu4CJtkB2zGsb+q6qhCVrFFVZuJSBWsttGNwHPYZE1jVfX8oON/XAGvF6Crqi6MJV7nwPsoXPrYB/g1SBKnA7vNCy42V/gvqvoK8Co2JeRk4GQRyelzqCoiDWLc5pfAeSJSRUSqYs1GX4rIocBmVX0TK8iY37zDO4Ijm/y8gxVjyzk6AfvS/0vOa0SkQbDNfKnNaHgz0Edyy+znlIvuGbHoBqwJLsco4K8SHF6JVR52LipPFC5dvAVkiMhs4ApgQT7LnAbMFJEZ2K/1Z1V1NfbFOVhEZmHNTkfHskFV/Rbru5iC9Vm8qqozgGOAKUET0IPAI/m8fAAwK6czO4/R2ORSn6tN3QmW2OYB34rIHKxsfNQj/iCWWdikPE8CjwXvPfJ1Y4FGOZ3Z2JFHhSC2ucF956Ly4bHOOeei8iMK55xzUXmicM45F5UnCuecc1F5onDOOReVJwrnnHNReaJwzjkXlScK55xzUf0/7yx3gby955AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfhm86fpCTgb"
      },
      "source": [
        "### **3.5. entrainement de notre modèle sur tous le dataset (trian +val)**¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EZh1dB0CYg1",
        "outputId": "f90262b0-1984-4af3-d520-00075542a599"
      },
      "source": [
        "# Concatenation de training set et du validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_discri_data, val_discri_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# entrainement sur tous le dataset\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
        "train(bert_classifier, full_train_dataloader, epochs=4)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.582839   |     -      |     -     |   8.86   \n",
            "   1    |   40    |   0.412828   |     -      |     -     |   8.48   \n",
            "   1    |   60    |   0.397053   |     -      |     -     |   8.52   \n",
            "   1    |   80    |   0.386111   |     -      |     -     |   8.60   \n",
            "   1    |   100   |   0.375520   |     -      |     -     |   8.66   \n",
            "   1    |   120   |   0.321995   |     -      |     -     |   8.71   \n",
            "   1    |   140   |   0.395715   |     -      |     -     |   8.80   \n",
            "   1    |   160   |   0.332135   |     -      |     -     |   8.88   \n",
            "   1    |   180   |   0.367693   |     -      |     -     |   8.98   \n",
            "   1    |   200   |   0.315409   |     -      |     -     |   8.96   \n",
            "   1    |   220   |   0.381190   |     -      |     -     |   8.95   \n",
            "   1    |   240   |   0.373051   |     -      |     -     |   8.82   \n",
            "   1    |   260   |   0.319025   |     -      |     -     |   8.78   \n",
            "   1    |   280   |   0.339333   |     -      |     -     |   8.84   \n",
            "   1    |   300   |   0.335432   |     -      |     -     |   8.83   \n",
            "   1    |   320   |   0.344692   |     -      |     -     |   8.84   \n",
            "   1    |   340   |   0.328498   |     -      |     -     |   8.93   \n",
            "   1    |   360   |   0.317282   |     -      |     -     |   8.85   \n",
            "   1    |   380   |   0.323329   |     -      |     -     |   8.84   \n",
            "   1    |   400   |   0.361469   |     -      |     -     |   8.84   \n",
            "   1    |   420   |   0.334009   |     -      |     -     |   8.84   \n",
            "   1    |   440   |   0.351406   |     -      |     -     |   8.86   \n",
            "   1    |   460   |   0.345707   |     -      |     -     |   8.84   \n",
            "   1    |   480   |   0.298622   |     -      |     -     |   8.82   \n",
            "   1    |   500   |   0.319210   |     -      |     -     |   8.85   \n",
            "   1    |   520   |   0.296735   |     -      |     -     |   8.86   \n",
            "   1    |   540   |   0.355655   |     -      |     -     |   8.85   \n",
            "   1    |   560   |   0.305205   |     -      |     -     |   8.83   \n",
            "   1    |   580   |   0.337861   |     -      |     -     |   8.83   \n",
            "   1    |   600   |   0.304922   |     -      |     -     |   8.88   \n",
            "   1    |   620   |   0.346360   |     -      |     -     |   8.82   \n",
            "   1    |   640   |   0.277737   |     -      |     -     |   8.85   \n",
            "   1    |   645   |   0.369963   |     -      |     -     |   1.96   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.231912   |     -      |     -     |   9.32   \n",
            "   2    |   40    |   0.217822   |     -      |     -     |   8.84   \n",
            "   2    |   60    |   0.235987   |     -      |     -     |   8.85   \n",
            "   2    |   80    |   0.270704   |     -      |     -     |   8.85   \n",
            "   2    |   100   |   0.241343   |     -      |     -     |   8.88   \n",
            "   2    |   120   |   0.229787   |     -      |     -     |   8.86   \n",
            "   2    |   140   |   0.201201   |     -      |     -     |   8.81   \n",
            "   2    |   160   |   0.234075   |     -      |     -     |   8.86   \n",
            "   2    |   180   |   0.203326   |     -      |     -     |   8.84   \n",
            "   2    |   200   |   0.245913   |     -      |     -     |   8.85   \n",
            "   2    |   220   |   0.217163   |     -      |     -     |   8.85   \n",
            "   2    |   240   |   0.272406   |     -      |     -     |   8.86   \n",
            "   2    |   260   |   0.210877   |     -      |     -     |   8.86   \n",
            "   2    |   280   |   0.222151   |     -      |     -     |   8.81   \n",
            "   2    |   300   |   0.227636   |     -      |     -     |   8.83   \n",
            "   2    |   320   |   0.242976   |     -      |     -     |   8.82   \n",
            "   2    |   340   |   0.238598   |     -      |     -     |   8.84   \n",
            "   2    |   360   |   0.204028   |     -      |     -     |   8.83   \n",
            "   2    |   380   |   0.175730   |     -      |     -     |   8.85   \n",
            "   2    |   400   |   0.202398   |     -      |     -     |   8.84   \n",
            "   2    |   420   |   0.211165   |     -      |     -     |   8.82   \n",
            "   2    |   440   |   0.211053   |     -      |     -     |   8.84   \n",
            "   2    |   460   |   0.247146   |     -      |     -     |   8.82   \n",
            "   2    |   480   |   0.184571   |     -      |     -     |   8.83   \n",
            "   2    |   500   |   0.210733   |     -      |     -     |   8.83   \n",
            "   2    |   520   |   0.193801   |     -      |     -     |   8.86   \n",
            "   2    |   540   |   0.236036   |     -      |     -     |   8.85   \n",
            "   2    |   560   |   0.190409   |     -      |     -     |   8.84   \n",
            "   2    |   580   |   0.206435   |     -      |     -     |   8.86   \n",
            "   2    |   600   |   0.195889   |     -      |     -     |   8.86   \n",
            "   2    |   620   |   0.163419   |     -      |     -     |   8.86   \n",
            "   2    |   640   |   0.259752   |     -      |     -     |   8.84   \n",
            "   2    |   645   |   0.345620   |     -      |     -     |   1.96   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.123323   |     -      |     -     |   9.28   \n",
            "   3    |   40    |   0.116367   |     -      |     -     |   8.86   \n",
            "   3    |   60    |   0.108458   |     -      |     -     |   8.87   \n",
            "   3    |   80    |   0.124228   |     -      |     -     |   8.84   \n",
            "   3    |   100   |   0.101979   |     -      |     -     |   8.85   \n",
            "   3    |   120   |   0.125410   |     -      |     -     |   8.84   \n",
            "   3    |   140   |   0.101953   |     -      |     -     |   8.84   \n",
            "   3    |   160   |   0.138283   |     -      |     -     |   8.85   \n",
            "   3    |   180   |   0.136043   |     -      |     -     |   8.84   \n",
            "   3    |   200   |   0.109319   |     -      |     -     |   8.81   \n",
            "   3    |   220   |   0.126274   |     -      |     -     |   8.84   \n",
            "   3    |   240   |   0.119455   |     -      |     -     |   8.86   \n",
            "   3    |   260   |   0.122389   |     -      |     -     |   8.86   \n",
            "   3    |   280   |   0.117803   |     -      |     -     |   8.85   \n",
            "   3    |   300   |   0.109449   |     -      |     -     |   8.85   \n",
            "   3    |   320   |   0.137817   |     -      |     -     |   8.83   \n",
            "   3    |   340   |   0.130851   |     -      |     -     |   8.85   \n",
            "   3    |   360   |   0.114490   |     -      |     -     |   8.85   \n",
            "   3    |   380   |   0.112203   |     -      |     -     |   8.85   \n",
            "   3    |   400   |   0.134071   |     -      |     -     |   8.81   \n",
            "   3    |   420   |   0.103785   |     -      |     -     |   8.86   \n",
            "   3    |   440   |   0.101033   |     -      |     -     |   8.84   \n",
            "   3    |   460   |   0.135873   |     -      |     -     |   8.82   \n",
            "   3    |   480   |   0.099127   |     -      |     -     |   8.84   \n",
            "   3    |   500   |   0.175117   |     -      |     -     |   8.87   \n",
            "   3    |   520   |   0.087353   |     -      |     -     |   8.84   \n",
            "   3    |   540   |   0.117326   |     -      |     -     |   8.86   \n",
            "   3    |   560   |   0.139136   |     -      |     -     |   8.85   \n",
            "   3    |   580   |   0.107292   |     -      |     -     |   8.90   \n",
            "   3    |   600   |   0.154042   |     -      |     -     |   8.86   \n",
            "   3    |   620   |   0.112124   |     -      |     -     |   8.85   \n",
            "   3    |   640   |   0.119803   |     -      |     -     |   8.84   \n",
            "   3    |   645   |   0.038304   |     -      |     -     |   1.95   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.044382   |     -      |     -     |   9.26   \n",
            "   4    |   40    |   0.055798   |     -      |     -     |   8.81   \n",
            "   4    |   60    |   0.048306   |     -      |     -     |   8.81   \n",
            "   4    |   80    |   0.040924   |     -      |     -     |   8.81   \n",
            "   4    |   100   |   0.074121   |     -      |     -     |   8.82   \n",
            "   4    |   120   |   0.040234   |     -      |     -     |   8.75   \n",
            "   4    |   140   |   0.102690   |     -      |     -     |   8.77   \n",
            "   4    |   160   |   0.034394   |     -      |     -     |   8.78   \n",
            "   4    |   180   |   0.050466   |     -      |     -     |   8.80   \n",
            "   4    |   200   |   0.080065   |     -      |     -     |   8.84   \n",
            "   4    |   220   |   0.043062   |     -      |     -     |   8.79   \n",
            "   4    |   240   |   0.068743   |     -      |     -     |   8.84   \n",
            "   4    |   260   |   0.047496   |     -      |     -     |   8.82   \n",
            "   4    |   280   |   0.044963   |     -      |     -     |   8.81   \n",
            "   4    |   300   |   0.127394   |     -      |     -     |   8.81   \n",
            "   4    |   320   |   0.065739   |     -      |     -     |   8.83   \n",
            "   4    |   340   |   0.064026   |     -      |     -     |   8.84   \n",
            "   4    |   360   |   0.056732   |     -      |     -     |   8.87   \n",
            "   4    |   380   |   0.065121   |     -      |     -     |   8.89   \n",
            "   4    |   400   |   0.101036   |     -      |     -     |   8.84   \n",
            "   4    |   420   |   0.126854   |     -      |     -     |   8.82   \n",
            "   4    |   440   |   0.092037   |     -      |     -     |   8.83   \n",
            "   4    |   460   |   0.086310   |     -      |     -     |   8.84   \n",
            "   4    |   480   |   0.088286   |     -      |     -     |   8.80   \n",
            "   4    |   500   |   0.110530   |     -      |     -     |   8.83   \n",
            "   4    |   520   |   0.049022   |     -      |     -     |   8.78   \n",
            "   4    |   540   |   0.078787   |     -      |     -     |   8.82   \n",
            "   4    |   560   |   0.051806   |     -      |     -     |   8.82   \n",
            "   4    |   580   |   0.041633   |     -      |     -     |   8.77   \n",
            "   4    |   600   |   0.074786   |     -      |     -     |   8.86   \n",
            "   4    |   620   |   0.059405   |     -      |     -     |   8.84   \n",
            "   4    |   640   |   0.116281   |     -      |     -     |   8.87   \n",
            "   4    |   645   |   0.086985   |     -      |     -     |   1.96   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            ">>>>>Training complete! in  0:18:59.655874  secondes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26loU_tZDo2c"
      },
      "source": [
        "### **4. Predictions sur le jeu de Test**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdjSjpAJDu8B",
        "outputId": "0d3005bd-933e-48ba-f913-8426b48568b0"
      },
      "source": [
        "# Lancement du `preprocessing_for_bert` sur notre jeu de test\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(data_test.Tweets)\n",
        "\n",
        "# Creation du DataLoader pour notre jeu de test\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>> La Tokenization à pris : 0:00:01.033647  secondes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrPnHMfMD4SG"
      },
      "source": [
        "### **4.2. Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77rOC6qeD_Zf",
        "outputId": "e60c9559-6af0-4c58-e242-569f40e50aa3"
      },
      "source": [
        "# Calcule de la probabilité sur le jeux de test\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "#Récupération de la prédiction issue de la softmax fonction (probabilité)\n",
        "threshold = 0.9\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Nombre de tweet mal prédit\n",
        "print(\"Numbre de tweets mal prédit : \", preds.sum())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbre de tweets mal prédit :  497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib-_WUoqz-Is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}